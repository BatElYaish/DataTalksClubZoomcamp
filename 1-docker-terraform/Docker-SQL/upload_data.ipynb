{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy.exc import OperationalError\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create sql engine and connection\n",
    "engine = create_engine('postgresql://postgres:postgres@localhost:5432/ny_taxi')\n",
    "try:\n",
    "    engine.connect()\n",
    "except OperationalError as e:\n",
    "    print(f\"Error connecting to the database: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load zones**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "zones_data = 'https://github.com/DataTalksClub/nyc-tlc-data/releases/download/misc/taxi_zone_lookup.csv'\n",
    "df_zones = pd.read_csv(zones_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "265"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_zones.to_sql(name='zones', con=engine, if_exists='replace')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load taxi data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#taxi info\n",
    "#Green data\n",
    "table_name = 'green_taxi_data'\n",
    "trips_data = 'https://github.com/DataTalksClub/nyc-tlc-data/releases/download/green/green_tripdata_2019-10.csv.gz'\n",
    "#Yellow data\n",
    "# table_name = 'yellow_taxi_data'\n",
    "# trips_data = 'https://github.com/DataTalksClub/nyc-tlc-data/releases/download/yellow/yellow_tripdata_2021-01.csv.gz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we only need first rows to get the schema\n",
    "df = pd.read_csv(trips_data, nrows=100, low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#datetime cols array\n",
    "dt_cols = [c for c in df.columns if 'datetime' in c]\n",
    "\n",
    "#convert to datetime\n",
    "for dt_c in dt_cols:\n",
    "    df[dt_c] = pd.to_datetime(df[dt_c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CREATE TABLE \"green_taxi_data\" (\n",
      "\"VendorID\" INTEGER,\n",
      "  \"lpep_pickup_datetime\" TIMESTAMP,\n",
      "  \"lpep_dropoff_datetime\" TIMESTAMP,\n",
      "  \"store_and_fwd_flag\" TEXT,\n",
      "  \"RatecodeID\" INTEGER,\n",
      "  \"PULocationID\" INTEGER,\n",
      "  \"DOLocationID\" INTEGER,\n",
      "  \"passenger_count\" INTEGER,\n",
      "  \"trip_distance\" REAL,\n",
      "  \"fare_amount\" REAL,\n",
      "  \"extra\" REAL,\n",
      "  \"mta_tax\" REAL,\n",
      "  \"tip_amount\" REAL,\n",
      "  \"tolls_amount\" REAL,\n",
      "  \"ehail_fee\" REAL,\n",
      "  \"improvement_surcharge\" REAL,\n",
      "  \"total_amount\" REAL,\n",
      "  \"payment_type\" INTEGER,\n",
      "  \"trip_type\" INTEGER,\n",
      "  \"congestion_surcharge\" REAL\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(pd.io.sql.get_schema(df, name=table_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#now we want to only create the table so we'll insert 0 rows of data, if the table exists then drop it and re-create the table\n",
    "df.head(n=0).to_sql(name = table_name, con=engine, if_exists='replace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set Chunck size\n",
    "chunk_size = 100000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read the df using an iterator because the data file is big\n",
    "df_iter = pd.read_csv(trips_data, iterator=True, chunksize=chunk_size, low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inserted another chunck, took 11.786005973815918 seconds, rows 0 - 100000\n",
      "inserted another chunck, took 13.880139350891113 seconds, rows 100000 - 200000\n",
      "inserted another chunck, took 13.477350950241089 seconds, rows 200000 - 300000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\batel\\AppData\\Local\\Temp\\ipykernel_4996\\3742408781.py:7: DtypeWarning: Columns (3) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df=next(df_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inserted another chunck, took 13.624748468399048 seconds, rows 300000 - 400000\n",
      "inserted another chunck, took 10.059311389923096 seconds, rows 400000 - 500000\n",
      "All chunks processed.\n"
     ]
    }
   ],
   "source": [
    "#load all iterations\n",
    "counter = 0\n",
    "while True:\n",
    "    try:\n",
    "        t_start = time()\n",
    "        #get the next iteration\n",
    "        df=next(df_iter)\n",
    "        #convert columns to datetime\n",
    "        for dt_c in dt_cols:\n",
    "            df[dt_c] = pd.to_datetime(df[dt_c])\n",
    "\n",
    "        #load data\n",
    "        df.to_sql(name = table_name, con=engine, if_exists='append')\n",
    "\n",
    "        t_took= time() - t_start\n",
    "        \n",
    "        print(f'Loaded rows {counter} - {counter+min(chunk_size,len(df))}. Process took {t_took:.2f} seconds.')\n",
    "        counter += min(chunk_size,len(df))\n",
    "    except StopIteration:\n",
    "        print(\"All chunks processed.\")\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
